# PRD: AI Readiness Report V2 (Web + PDF)

## 1. Problem

Current AI Readiness report has two core issues:

1. **Black-box scores**  
   Users see overall and pillar scores but cannot see how their answers contributed.
   - No way to review "what did I actually say?"  
   - No audit trail to support internal conversations or challenge/refine inputs.

2. **Low-impact PDF**  
   The generated PDF is technically correct but visually flat.  
   - Feels like a debug export, not a shareable artifact.  
   - Doesn't reflect the quality of the web experience.  
   - Not compelling enough to trigger "forward to my team" behaviour.

Result: we miss the opportunity for the report to become:

- A trusted diagnostic (transparent)
- A conversation tool (designed for sharing)
- A brand moment ("wow, this feels premium")

---

## 2. Goals

1. **Transparency**
   - Users can see the exact answers that led to their scores.
   - Every answered question is visible somewhere on the report and/or PDF.

2. **Shareable, premium PDF**
   - First page feels like a polished strategy slide.
   - Designed to be shared internally (Slack/email) without extra explanation.

3. **Conversation catalyst**
   - Report explicitly encourages discussion and next steps.
   - Includes prompts and space for "what we'll do with this".

4. **Foundations for future interactivity**
   - Data structures and UX leave room for later "edit answers & regenerate" flows.
   - No choices that would block moving to a dynamic report later.

---

## 3. Non-goals (V2)

- Editable answers on the report page (no "inline quiz editing" yet).
- Multi-user collaboration / comments.
- Per-tenant theming (stick with Accelerator theme).
- Deep analytics or longitudinal comparison across multiple reports.

---

## 4. Target Users & Use Cases

### Primary user: Senior leader who completed the quiz

- Wants to understand "why did we get this band / these scores?"
- Wants something credible to show colleagues.

### Secondary user: Colleague receiving the PDF

- Skims page 1 in < 30 seconds.
- May flip to answer appendix to see "what did we actually say?"

---

## 5. Experience Overview

### 5.1 Web: "How we calculated your scores" transparency

**Location:** `/report/[token]`, below existing narrative content.

#### Section: "How we calculated your scores"

- For each pillar:
  - Pillar label + score badge (e.g. `Leadership 2.4 / 5`).
  - Collapsible panel:
    - For each question in that pillar:
      - Question text.
      - User's selected answer, rendered as:
        - Option label for multiple choice / radio.
        - Entered text/number for freeform.
      - Optional meta: "Contributes to: [Pillar]".

**Behaviour:**

- All panels collapsed by default to keep page compact.
- Clicking a pillar expands/collapses its Q&A.
- No editing. Read-only.

**Copy example:**

- Section heading: `How we calculated your scores`
- Helper text:  
  "These are the answers you gave. Use this view to sense-check your scores and discuss with your team."

---

### 5.2 PDF page structure

#### Page 1: Executive Snapshot

Purpose: shareable "slide" summarising the result.

Layout:

1. **Hero band**
   - Left: logo + "AI Readiness Report".
   - Right: large score badge (`43%: Emerging`).
   - Subline: "Based on 30 question assessment completed on [date]."

2. **Summary block (top-left)**
   - Section label: `SUMMARY`
   - 2 band-specific headline sentences.
   - 2 bullets: "What this really means".

3. **Pillar chart (top-right)**
   - Horizontal bar chart: each pillar 5.
   - Legend explaining scale.

4. **Strengths & Risks (bottom-left)**
   - `STRENGTHS` 2-3 bullets.
   - `RISKS` 2-3 bullets.

5. **Next 90 Days (bottom-right)**
   - `IF YOU DO ONE THING NEXT` 1 sentence.
   - 3-step mini roadmap: 0 days, 30 days, 60 days.

6. **Footer**
   - Prepared for: Name, Company, Email.
   - Token / internal ID.
   - "Generated by ScoreKit [url]".

#### Page 2: Pillar Deep Dive

Purpose: high-level context per pillar.

Per pillar:

- Pillar name + score badge.
- One sentence diagnosis.
- 2 bullets:
  - "You said" style, summarising key answer patterns.
  - Tied back to template content.

Visual: stacked blocks, 2 columns on desktop, 1 column on narrow widths.

#### Page 3: Answer Appendix

Purpose: full transparency.

Grouped by pillar:

- Pillar heading.
- For each question:
  - Question text (possibly shortened).
  - Answer rendered in a shaded box.
  - For low scores or critical flags, small icon or emphasis.

This page can be text-heavy; priority is completeness and legibility.

---

## 6. Data & Technical Considerations

### 6.1 Brand packs per template

Each assessment template must define a **brand pack** so we can reuse the same PDF layout across multiple brands without changing PDF code.

Add a `brand` block to template content (shape may live in core types):

```ts
type TemplateBrand = {
  logo: {
    light?: string; // for use on dark backgrounds
    dark?: string;  // for use on light backgrounds
  };
  colors: {
    primary: string;
    secondary?: string;
    accent?: string;
    text: string;
    mutedText: string;
    background: string;
    surface: string;
  };
  typography?: {
    displayFont?: string;
    bodyFont?: string;
  };
};
```

Example for the AI Readiness / Accelerator template:

```ts
brand: {
  logo: {
    light: "/logos/accelerator.svg",
    dark: "/logos/accelerator.svg",
  },
  colors: {
    primary: "#4f46e5",
    secondary: "#0f172a",
    accent: "#22c55e",
    text: "#111827",
    mutedText: "#6b7280",
    background: "#ffffff",
    surface: "#f9fafb",
  },
  typography: {
    displayFont: "Spline Sans",
    bodyFont: "Inter",
  },
}
```

### 6.2 PDF theme abstraction

The PDF generator must not hard-code brand colours or logo paths. Instead it uses a **PdfTheme** built from the template brand pack:

```ts
type PdfTheme = {
  colors: {
    pageBg: string;
    headerBg: string;
    headerText: string;
    primary: string;
    text: string;
    mutedText: string;
    border: string;
    badgeBg: string;
    badgeText: string;
    surface: string;
  };
  logo?: {
    src?: string;
    width?: number;
    height?: number;
  };
  typography?: {
    displayFont?: string;
    bodyFont?: string;
  };
};
```

Builder function:

```ts
function buildPdfThemeFromTemplate(content: TemplateContent): PdfTheme {
  // Map content.brand.* into PdfTheme, with sensible fallbacks
}
```

**Rule:** All PDF drawing code must use values from `PdfTheme` (or neutrals like pure white/black where appropriate), not raw hex codes tied to a single client.

### 6.3 Data & mapping

- Ensure `ReportRecord` includes:
  - Full answer map (question ID -> answer).
  - Ability to map each question to a pillar and category (already in template).
- For PDF:
  - PDF render function must receive both `result` and raw `answers`.
  - Answer text must be derived from template (option labels) not raw numeric values.
- Use `mapAnswersToPillars` from `@scorekit/core` as the single source for building the answer appendix data structure.

### 6.4 PDF page renderers

Implementation should organise the PDF route into page-level render functions that all receive the same `PdfTheme`:

- `renderPage1ExecutiveSnapshot(doc, theme, report, templateContent)`
- `renderPage2PillarDeepDive(doc, theme, report, templateContent)`
- `renderPage3AnswerAppendix(doc, theme, mappedAnswers)`

This keeps layout concerns separate from data mapping and makes it easier to apply new brand packs/templates later.

---

## 7. Acceptance Criteria

### Web report

- [ ] Every answered question appears in the "How we calculated your scores" section, grouped by pillar.
- [ ] For each pillar, the user can expand/collapse to see their answers.
- [ ] Option questions show human-readable labels, not internal IDs.
- [ ] No editing is possible in V2.
- [ ] Works on mobile and desktop without layout breakage.
- [ ] No additional network calls beyond the existing report load.

### PDF

- [ ] PDF contains exactly 3 pages for a complete report.
- [ ] Page 1 includes:
  - [ ] Title, score badge, date.
  - [ ] Summary copy from template.
  - [ ] Pillar chart.
  - [ ] Strengths, Risks, Next 90 Days.
- [ ] Page 2 includes all pillars with:
  - [ ] Name, score, and short narrative.
- [ ] Page 3 includes 100% of answered questions:
  - [ ] Grouped by pillar.
  - [ ] Question text + human-readable answer.
- [ ] Route `/api/report/pdf` fails fast if any required data is missing (e.g. answers absent).

---

## 8. Testing Strategy (hooks)

- Unit tests for **answer mapping**:
  - Given a mock template + answers, we can produce:
    - Pillar -> questions list.
    - Question -> display label + display answer.
- Component test for **web "Your answers" section**:
  - Renders correct groups and answers.
  - Collapsing/expanding works.
- Integration test for **PDF route**:
  - With mock report including answers, endpoint returns 200 and non-empty PDF bytes.
  - With missing answers, returns 400/500 with clear JSON error.
- Visual/manual:
  - UAT checklist for both web and PDF (desktop + mobile preview, share test).

---

## 9. Open Questions

- Do we want to expose *all* answers, or only selected "diagnostic" ones in the appendix?
- Any redaction needed for free text answers (e.g. names, sensitive content)?
- Do we want band-specific colour accents (e.g. red for low, gold for high)?
- Should we include a client-facing link back to a live version of the report from the PDF?
